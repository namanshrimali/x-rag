{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from utils import get_device, seed_all\n",
    "from models import get_latest_checkpoint, GetEncodings, BARTTrain\n",
    "import pandas as pd\n",
    "\n",
    "seed_all()\n",
    "device = get_device()\n",
    "\n",
    "# Inference\n",
    "MODEL_STORE = '/content/drive/MyDrive/END2_CAPSTONE'\n",
    "\n",
    "bart_model = BARTTrain().to(device)\n",
    "\n",
    "bart_model = get_latest_checkpoint('checkpoint', bart_model, MODEL_STORE)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "device is cpu\n",
      "No checkpoints available right now\n",
      "Currently Running on cpu\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pg/tbgv3_8n2kg77xkdv85jvcb00000gn/T/ipykernel_6070/44544048.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/END2_CAPSTONE/context_groups.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdf_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/END2_CAPSTONE/merged_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/END2_CAPSTONE/np_encoded_context.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_context = pd.read_csv('/content/drive/MyDrive/END2_CAPSTONE/context_groups.csv') \n",
    "df_merged = pd.read_csv('/content/drive/MyDrive/END2_CAPSTONE/merged_data.csv')\n",
    "model_op = torch.load('/content/drive/MyDrive/END2_CAPSTONE/np_encoded_context.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def inference(question, bart_tokenizer, bart_model):\n",
    "\n",
    "    # Get Pretrained BERT encodings\n",
    "\n",
    "    ge = GetEncodings(type='questions')\n",
    "    encoded_question = ge.encode(question, max_length=30)\n",
    "\n",
    "    # Find top matching documents\n",
    "    ss = SearchSimilar(iterator = df_context['context'].values.tolist(), filename='index.bin', embeddings=model_op, shape=768, device=device)\n",
    "    similar_contexts = ss.get_n_similar_vectors(encoded_question, 3)\n",
    "    similar_contexts.insert(0, question)\n",
    "\n",
    "    combined_tokens = '</s></s>'.join(similar_contexts)\n",
    "\n",
    "    print(f'Top similar document outputs is {combined_tokens}')\n",
    "\n",
    "    # Prepare data for BART Inferencing\n",
    "\n",
    "    source_encoding = bart_tokenizer(\n",
    "            combined_tokens,\n",
    "            max_length=1024,\n",
    "            padding='max_length',\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\")\n",
    "   \n",
    "\n",
    "    # Inference BART Model\n",
    "    output = bart_model(source_encoding['input_ids'].to(device), mode = 'eval')\n",
    "    output = bart_tokenizer.decode(output[0])\n",
    "    print(output)\n",
    "    return output\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokens = inference('What does torch.cosine loss do in pytorch?', tokenizer, bart_model)\n",
    "\n",
    "# Loss plots\n",
    "\n",
    "\n",
    "loss_qna = torch.load('/content/drive/MyDrive/END2_CAPSTONE/qna_checkpoint-4000/training_loss.pt')\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('caps': conda)"
  },
  "interpreter": {
   "hash": "d964e81d6599016aee694e721ea343ca3a42c4f371ca966a53ff9f7507121df1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}