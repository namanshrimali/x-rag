{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "file_path = 'data/final_pd.csv'\n",
    "\n",
    "df_all = pd.read_csv(file_path)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "df_all"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>In what platform do the key nn modules run?</td>\n",
       "      <td>FP32</td>\n",
       "      <td>torch.nn.intrinsic.qat This module implements ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What module implements versions of the key nn ...</td>\n",
       "      <td>torch.nn.quantized</td>\n",
       "      <td>This module implements the functions you call ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What is needed for quantization aware training?</td>\n",
       "      <td>fused operations</td>\n",
       "      <td>This module implements the versions of those f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Conv2d and Linear() use rounding to simulate t...</td>\n",
       "      <td>INT8 quantization</td>\n",
       "      <td>This module implements the versions of those f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What module implements versions of the key nn ...</td>\n",
       "      <td>torch.nn.quantized</td>\n",
       "      <td>This module implements the functions you call ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25060</th>\n",
       "      <td>95</td>\n",
       "      <td>ptorch geometric has multiple gpu support?</td>\n",
       "      <td>PyTorch Geometric (PyG) is a geometric deep l...</td>\n",
       "      <td>PyTorch Geometric (PyG) is a geometric deep le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25061</th>\n",
       "      <td>96</td>\n",
       "      <td>Is ptorch geometric compatible with many GPUs?</td>\n",
       "      <td>PyTorch Geometric (PyG) is a geometric deep l...</td>\n",
       "      <td>PyTorch Geometric (PyG) is a geometric deep le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25062</th>\n",
       "      <td>97</td>\n",
       "      <td>are multiple gpus compatible with pytorch geom...</td>\n",
       "      <td>PyTorch Geometric (PyG) is a geometric deep l...</td>\n",
       "      <td>PyTorch Geometric (PyG) is a geometric deep le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25063</th>\n",
       "      <td>98</td>\n",
       "      <td>multiple gpus compatible with pytorch geometric?</td>\n",
       "      <td>PyTorch Geometric (PyG) is a geometric deep l...</td>\n",
       "      <td>PyTorch Geometric (PyG) is a geometric deep le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25064</th>\n",
       "      <td>99</td>\n",
       "      <td>multiple gpus are compatible with pytorch geom...</td>\n",
       "      <td>PyTorch Geometric (PyG) is a geometric deep l...</td>\n",
       "      <td>PyTorch Geometric (PyG) is a geometric deep le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25065 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                           question  \\\n",
       "0               0        In what platform do the key nn modules run?   \n",
       "1               1  What module implements versions of the key nn ...   \n",
       "2               2    What is needed for quantization aware training?   \n",
       "3               3  Conv2d and Linear() use rounding to simulate t...   \n",
       "4               4  What module implements versions of the key nn ...   \n",
       "...           ...                                                ...   \n",
       "25060          95         ptorch geometric has multiple gpu support?   \n",
       "25061          96    Is ptorch geometric compatible with many GPUs?    \n",
       "25062          97  are multiple gpus compatible with pytorch geom...   \n",
       "25063          98  multiple gpus compatible with pytorch geometric?    \n",
       "25064          99  multiple gpus are compatible with pytorch geom...   \n",
       "\n",
       "                                                  answer  \\\n",
       "0                                                   FP32   \n",
       "1                                     torch.nn.quantized   \n",
       "2                                       fused operations   \n",
       "3                                      INT8 quantization   \n",
       "4                                     torch.nn.quantized   \n",
       "...                                                  ...   \n",
       "25060   PyTorch Geometric (PyG) is a geometric deep l...   \n",
       "25061   PyTorch Geometric (PyG) is a geometric deep l...   \n",
       "25062   PyTorch Geometric (PyG) is a geometric deep l...   \n",
       "25063   PyTorch Geometric (PyG) is a geometric deep l...   \n",
       "25064   PyTorch Geometric (PyG) is a geometric deep l...   \n",
       "\n",
       "                                                 context  \n",
       "0      torch.nn.intrinsic.qat This module implements ...  \n",
       "1      This module implements the functions you call ...  \n",
       "2      This module implements the versions of those f...  \n",
       "3      This module implements the versions of those f...  \n",
       "4      This module implements the functions you call ...  \n",
       "...                                                  ...  \n",
       "25060  PyTorch Geometric (PyG) is a geometric deep le...  \n",
       "25061  PyTorch Geometric (PyG) is a geometric deep le...  \n",
       "25062  PyTorch Geometric (PyG) is a geometric deep le...  \n",
       "25063  PyTorch Geometric (PyG) is a geometric deep le...  \n",
       "25064  PyTorch Geometric (PyG) is a geometric deep le...  \n",
       "\n",
       "[25065 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "df_all1 = df_all.sample(frac=1).reset_index(drop=True)[['question', 'answer', 'context']].reset_index().rename(columns={'index': 'id'})\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "df_all1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[JIT]torch._C._infer_size throws an exception ...</td>\n",
       "      <td>You need to pass tensors with the correct shap...</td>\n",
       "      <td>Got it! I think this should work fine for most...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What does TheExtending TorchScript with Custom...</td>\n",
       "      <td>OpenCV</td>\n",
       "      <td>TorchScript can be augmented with user-supplie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RuntimeError: cuda runtime error (3) : initial...</td>\n",
       "      <td>Hopefully, I'll be able to remark on why it w...</td>\n",
       "      <td>&gt; @zhangguanheng66 can hopefully comment on wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What is the TorchScript method that indicates ...</td>\n",
       "      <td>a pass-through function that returnsvalue</td>\n",
       "      <td>Scripting a function ornn.Modulewill inspect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What is the input tensor called?</td>\n",
       "      <td>input(Tensor)</td>\n",
       "      <td>This function is different fromtorch.unique_co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25060</th>\n",
       "      <td>25060</td>\n",
       "      <td>Ruby Library</td>\n",
       "      <td>Users can execute :\\r\\n\\r\\n```sh\\r\\nbrew insta...</td>\n",
       "      <td>Also added a Homebrew formula so users can now...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25061</th>\n",
       "      <td>25061</td>\n",
       "      <td>Different behaviour of BCEWithLogitsLoss and B...</td>\n",
       "      <td>The behavior is same if `binary_cross_entropy`...</td>\n",
       "      <td>Thanks for reporting this @martinarjovsky.\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25062</th>\n",
       "      <td>25062</td>\n",
       "      <td>c10 macros cmake macros h not exists</td>\n",
       "      <td>I have a CPP android project. I’m compiling it...</td>\n",
       "      <td>I found a related post with link https://discu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25063</th>\n",
       "      <td>25063</td>\n",
       "      <td>[pytorch] Incorrect error message in NLL_Loss</td>\n",
       "      <td>Closed by #6617.</td>\n",
       "      <td>Closed by #6617. Thanks for the report, @pilou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25064</th>\n",
       "      <td>25064</td>\n",
       "      <td>nn.Conv1d Applies a what convolution over an i...</td>\n",
       "      <td>1D</td>\n",
       "      <td>Normalization Layers Recurrent Layers Transfor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25065 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                           question  \\\n",
       "0          0  [JIT]torch._C._infer_size throws an exception ...   \n",
       "1          1  What does TheExtending TorchScript with Custom...   \n",
       "2          2  RuntimeError: cuda runtime error (3) : initial...   \n",
       "3          3  What is the TorchScript method that indicates ...   \n",
       "4          4                   What is the input tensor called?   \n",
       "...      ...                                                ...   \n",
       "25060  25060                                       Ruby Library   \n",
       "25061  25061  Different behaviour of BCEWithLogitsLoss and B...   \n",
       "25062  25062               c10 macros cmake macros h not exists   \n",
       "25063  25063      [pytorch] Incorrect error message in NLL_Loss   \n",
       "25064  25064  nn.Conv1d Applies a what convolution over an i...   \n",
       "\n",
       "                                                  answer  \\\n",
       "0      You need to pass tensors with the correct shap...   \n",
       "1                                                 OpenCV   \n",
       "2       Hopefully, I'll be able to remark on why it w...   \n",
       "3              a pass-through function that returnsvalue   \n",
       "4                                          input(Tensor)   \n",
       "...                                                  ...   \n",
       "25060  Users can execute :\\r\\n\\r\\n```sh\\r\\nbrew insta...   \n",
       "25061  The behavior is same if `binary_cross_entropy`...   \n",
       "25062  I have a CPP android project. I’m compiling it...   \n",
       "25063                                  Closed by #6617.    \n",
       "25064                                                 1D   \n",
       "\n",
       "                                                 context  \n",
       "0      Got it! I think this should work fine for most...  \n",
       "1      TorchScript can be augmented with user-supplie...  \n",
       "2      > @zhangguanheng66 can hopefully comment on wh...  \n",
       "3        Scripting a function ornn.Modulewill inspect...  \n",
       "4      This function is different fromtorch.unique_co...  \n",
       "...                                                  ...  \n",
       "25060  Also added a Homebrew formula so users can now...  \n",
       "25061  Thanks for reporting this @martinarjovsky.\\n\\n...  \n",
       "25062  I found a related post with link https://discu...  \n",
       "25063  Closed by #6617. Thanks for the report, @pilou...  \n",
       "25064  Normalization Layers Recurrent Layers Transfor...  \n",
       "\n",
       "[25065 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "df_groups = df_all1.groupby('context')['id'].apply(list).reset_index(name = 'groups')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "df_groups = df_all1.groupby('context')['id'].apply(list).reset_index(name = 'groups')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "df_groups"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nThe implementation should allow for the outp...</td>\n",
       "      <td>[4345, 21075]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wrapper around C++torch::jit::Module.   Fu...</td>\n",
       "      <td>[5199, 16338, 21083]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alias for torch.asinh().   Returns a new ten...</td>\n",
       "      <td>[4238, 5014, 7191, 7833, 10042, 10703, 11281, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alias fortorch.asinh().   Returns a new tens...</td>\n",
       "      <td>[12611, 14119, 20135, 20492]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alias fortorch.asinh().   Returns a new tens...</td>\n",
       "      <td>[24718]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11491</th>\n",
       "      <td>’fro’ Frobenius norm – ‘nuc’ nuclear norm – Nu...</td>\n",
       "      <td>[23962]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11492</th>\n",
       "      <td>”ReLU(x + 1): (int)”\\nwhen printing Measuremen...</td>\n",
       "      <td>[69]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11493</th>\n",
       "      <td>…\\nreturn x m = Model()\\nk = torch.randn(2, 3)...</td>\n",
       "      <td>[20125]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11494</th>\n",
       "      <td>… return x m = Model() k = torch.randn(2, 3) x...</td>\n",
       "      <td>[12288]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11495</th>\n",
       "      <td>👍 for making `nonzero()` compatible with numpy...</td>\n",
       "      <td>[17148, 17832]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11496 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 context  \\\n",
       "0      \\nThe implementation should allow for the outp...   \n",
       "1        A wrapper around C++torch::jit::Module.   Fu...   \n",
       "2        Alias for torch.asinh().   Returns a new ten...   \n",
       "3        Alias fortorch.asinh().   Returns a new tens...   \n",
       "4        Alias fortorch.asinh().   Returns a new tens...   \n",
       "...                                                  ...   \n",
       "11491  ’fro’ Frobenius norm – ‘nuc’ nuclear norm – Nu...   \n",
       "11492  ”ReLU(x + 1): (int)”\\nwhen printing Measuremen...   \n",
       "11493  …\\nreturn x m = Model()\\nk = torch.randn(2, 3)...   \n",
       "11494  … return x m = Model() k = torch.randn(2, 3) x...   \n",
       "11495  👍 for making `nonzero()` compatible with numpy...   \n",
       "\n",
       "                                                  groups  \n",
       "0                                          [4345, 21075]  \n",
       "1                                   [5199, 16338, 21083]  \n",
       "2      [4238, 5014, 7191, 7833, 10042, 10703, 11281, ...  \n",
       "3                           [12611, 14119, 20135, 20492]  \n",
       "4                                                [24718]  \n",
       "...                                                  ...  \n",
       "11491                                            [23962]  \n",
       "11492                                               [69]  \n",
       "11493                                            [20125]  \n",
       "11494                                            [12288]  \n",
       "11495                                     [17148, 17832]  \n",
       "\n",
       "[11496 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "df_groups = df_groups.reset_index().rename(columns={'index': 'group_id'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "df_groups.to_csv('context_groups.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "df_merged = pd.merge(df_all1, df_groups).reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "df_merged = df_merged[['question', 'answer', 'group_id']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "df_train, df_val = train_test_split(df_merged, test_size=0.3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "df_train.to_csv('data/train/train.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "df_val.to_csv('data/val/val.csv')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('caps': conda)"
  },
  "interpreter": {
   "hash": "d964e81d6599016aee694e721ea343ca3a42c4f371ca966a53ff9f7507121df1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}